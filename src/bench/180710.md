```clojure
{
  :transit-summary
    {:mean 14.72,
     :sigma 7.080018832366669,
     :iterations/trial 100,
     :expr (let [writer (transit/writer :json)
                 reader (transit/reader :json)]
                 (transit/read reader (transit/write writer data))),
     :trials 25},

 :fress-summary
   {:mean 26.68,
    :sigma 12.338017128642132,
    :iterations/trial 100,
    :expr (let [bs (fress/byte-stream)]
            (fress/write-object (fress/create-writer bs) data)
            (fress/read-object (fress/create-reader bs))),
    :trials 25},

  :arch nil,
  :platform linux,
  :node-version v9.10.1}

```

## `0.1.0`

+ Transit runs in about half the time. JSON.parse can probably allocate js structs much faster than user code. JS objects in particular seem much faster via json. For writing, transit gets to lean on JSON.stringify

+ transit-js is impressively well written, lots to learn from it

+ Fress raw utf8 seems to be alittle faster. Other primitives are a wash.

+ lots of low hangin fruit, like disabling writer checksum

+ A big source of inefficiency is the byte-stream. We allocate a plain array and when finished writing, we allocate an array buffer an put a view on it. This will not be normal usage with wasm; writing to memory is simply passing bytes to a module fn, and reading will occur on views over an existing memory slab, there will be no substrate allocation. Its however possible that it will be faster for wasm to actually write transit instead of fressian :-\

### update

if we recycle the bytestream between iterations, its on par with transit

```clojure
{:fress-reset-summary
  {:mean 15.64,
   :sigma 3.365016097039261,
   :iterations/trial 100,
   :trials 25,
   :expr (do
           (fress/write-object (fress/create-writer bs) data)
           (fress/read-object (fress/create-reader bs))
           (buf/reset bs))}}

```
